As we already discussed the algorithm evaluation results before, we here mainly examines results in our user study.
The quantitative results confirm that CodeGlass fully outperformed in history understanding.
Our user evaluation showed that CodeGlass significantly improves the recall of implementation rationale understanding, but not precision.
One possible reason was that implementation rationales can be inferred to some extent if execution was well understood.
As a result, the reference condition might have shown comparable precision results.
Because we observed a difference in recall, we conclude that our CodeGlass showed partial outperformance in rationale understanding.

Recall was rather low across the conditions.
One possible explanation was that our user study had time limits to make the evaluation tractable.
But, our results are still positive because participants were able to develop precise understanding in all three information categories with CodeGlass.

The confidence scores showed differences in the history understanding.
93.5\% and 90.8\% of the documented items by participants had confidence scores of 50 and above in the reference and CodeGlass condition, respectively.
This suggests that the participants tended to document only items on which they had a certain level of confidence.
The confidence scores for history understanding in the reference condition was an exception because many participants simply failed to identify any item in the reference condition.
This result also confirms the advantages of CodeGlass.
